{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e646dab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.136164Z",
     "start_time": "2022-11-13T10:50:18.844464Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Layer,Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3523f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.226571Z",
     "start_time": "2022-11-13T10:50:29.137521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('forestfires (1).csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b46ff24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.278655Z",
     "start_time": "2022-11-13T10:50:29.241118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['size_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e0a9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.336614Z",
     "start_time": "2022-11-13T10:50:29.289523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4352cc6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.411498Z",
     "start_time": "2022-11-13T10:50:29.342487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0              0  \n",
       "1           0              0  \n",
       "2           0              0  \n",
       "3           0              0  \n",
       "4           0              0  \n",
       "..        ...            ...  \n",
       "512         0              1  \n",
       "513         0              1  \n",
       "514         0              1  \n",
       "515         0              0  \n",
       "516         0              0  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['size_category']=np.where(df['size_category'].str.contains('small'),0,1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513c1bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.459366Z",
     "start_time": "2022-11-13T10:50:29.419464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    378\n",
       "1    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['size_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e863486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.612253Z",
     "start_time": "2022-11-13T10:50:29.469434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>0.268859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "      <td>0.443796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthfeb  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.038685   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.193029   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthjan    monthjul    monthjun    monthmar    monthmay    monthnov  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.003868    0.061896    0.032882    0.104449    0.003868    0.001934   \n",
       "std      0.062137    0.241199    0.178500    0.306138    0.062137    0.043980   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthoct    monthsep  size_category  \n",
       "count  517.000000  517.000000     517.000000  \n",
       "mean     0.029014    0.332689       0.268859  \n",
       "std      0.168007    0.471632       0.443796  \n",
       "min      0.000000    0.000000       0.000000  \n",
       "25%      0.000000    0.000000       0.000000  \n",
       "50%      0.000000    0.000000       0.000000  \n",
       "75%      0.000000    1.000000       1.000000  \n",
       "max      1.000000    1.000000       1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1753f715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.648409Z",
     "start_time": "2022-11-13T10:50:29.616506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    int32  \n",
      "dtypes: float64(8), int32(1), int64(20), object(2)\n",
      "memory usage: 123.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafbe175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.665351Z",
     "start_time": "2022-11-13T10:50:29.653164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d996d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.694862Z",
     "start_time": "2022-11-13T10:50:29.672938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 29 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   FFMC           517 non-null    float64\n",
      " 1   DMC            517 non-null    float64\n",
      " 2   DC             517 non-null    float64\n",
      " 3   ISI            517 non-null    float64\n",
      " 4   temp           517 non-null    float64\n",
      " 5   RH             517 non-null    int64  \n",
      " 6   wind           517 non-null    float64\n",
      " 7   rain           517 non-null    float64\n",
      " 8   area           517 non-null    float64\n",
      " 9   dayfri         517 non-null    int64  \n",
      " 10  daymon         517 non-null    int64  \n",
      " 11  daysat         517 non-null    int64  \n",
      " 12  daysun         517 non-null    int64  \n",
      " 13  daythu         517 non-null    int64  \n",
      " 14  daytue         517 non-null    int64  \n",
      " 15  daywed         517 non-null    int64  \n",
      " 16  monthapr       517 non-null    int64  \n",
      " 17  monthaug       517 non-null    int64  \n",
      " 18  monthdec       517 non-null    int64  \n",
      " 19  monthfeb       517 non-null    int64  \n",
      " 20  monthjan       517 non-null    int64  \n",
      " 21  monthjul       517 non-null    int64  \n",
      " 22  monthjun       517 non-null    int64  \n",
      " 23  monthmar       517 non-null    int64  \n",
      " 24  monthmay       517 non-null    int64  \n",
      " 25  monthnov       517 non-null    int64  \n",
      " 26  monthoct       517 non-null    int64  \n",
      " 27  monthsep       517 non-null    int64  \n",
      " 28  size_category  517 non-null    int32  \n",
      "dtypes: float64(8), int32(1), int64(20)\n",
      "memory usage: 115.2 KB\n"
     ]
    }
   ],
   "source": [
    "df1=df.iloc[:,2:]\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b97774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.758918Z",
     "start_time": "2022-11-13T10:50:29.695900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.086492</td>\n",
       "      <td>0.101325</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192926</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.927742</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>0.775419</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.508039</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.927742</td>\n",
       "      <td>0.146795</td>\n",
       "      <td>0.796294</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.398714</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.110958</td>\n",
       "      <td>0.081623</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>0.196141</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.172984</td>\n",
       "      <td>0.110590</td>\n",
       "      <td>0.171123</td>\n",
       "      <td>0.295820</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.049769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.976774</td>\n",
       "      <td>0.499311</td>\n",
       "      <td>0.711622</td>\n",
       "      <td>0.201426</td>\n",
       "      <td>0.752412</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.784516</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.308682</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.870968  0.086492  0.101325  0.090909  0.192926  0.423529  0.700000   \n",
       "1    0.927742  0.118194  0.775419  0.119430  0.508039  0.211765  0.055556   \n",
       "2    0.927742  0.146795  0.796294  0.119430  0.398714  0.211765  0.100000   \n",
       "3    0.941935  0.110958  0.081623  0.160428  0.196141  0.964706  0.400000   \n",
       "4    0.910968  0.172984  0.110590  0.171123  0.295820  0.988235  0.155556   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512  0.811613  0.191592  0.771315  0.033868  0.823151  0.200000  0.255556   \n",
       "513  0.811613  0.191592  0.771315  0.033868  0.633441  0.658824  0.600000   \n",
       "514  0.811613  0.191592  0.771315  0.033868  0.610932  0.647059  0.700000   \n",
       "515  0.976774  0.499311  0.711622  0.201426  0.752412  0.317647  0.400000   \n",
       "516  0.784516  0.006547  0.115867  0.019608  0.308682  0.188235  0.455556   \n",
       "\n",
       "          7         8    9   ...   19   20   21   22   23   24   25   26   27  \\\n",
       "0    0.00000  0.000000  1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1    0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2    0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "3    0.03125  0.000000  1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "4    0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "..       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "512  0.00000  0.005904  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "513  0.00000  0.049769  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "514  0.00000  0.010231  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "515  0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "516  0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "      28  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "..   ...  \n",
       "512  1.0  \n",
       "513  1.0  \n",
       "514  1.0  \n",
       "515  0.0  \n",
       "516  0.0  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm=MinMaxScaler()\n",
    "df2=pd.DataFrame(norm.fit_transform(df1))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5b50f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.816563Z",
     "start_time": "2022-11-13T10:50:29.761994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.086492</td>\n",
       "      <td>0.101325</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192926</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.927742</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>0.775419</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.508039</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.927742</td>\n",
       "      <td>0.146795</td>\n",
       "      <td>0.796294</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.398714</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.110958</td>\n",
       "      <td>0.081623</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>0.196141</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.172984</td>\n",
       "      <td>0.110590</td>\n",
       "      <td>0.171123</td>\n",
       "      <td>0.295820</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.823151</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.049769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.191592</td>\n",
       "      <td>0.771315</td>\n",
       "      <td>0.033868</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.976774</td>\n",
       "      <td>0.499311</td>\n",
       "      <td>0.711622</td>\n",
       "      <td>0.201426</td>\n",
       "      <td>0.752412</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.784516</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.308682</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.870968  0.086492  0.101325  0.090909  0.192926  0.423529  0.700000   \n",
       "1    0.927742  0.118194  0.775419  0.119430  0.508039  0.211765  0.055556   \n",
       "2    0.927742  0.146795  0.796294  0.119430  0.398714  0.211765  0.100000   \n",
       "3    0.941935  0.110958  0.081623  0.160428  0.196141  0.964706  0.400000   \n",
       "4    0.910968  0.172984  0.110590  0.171123  0.295820  0.988235  0.155556   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512  0.811613  0.191592  0.771315  0.033868  0.823151  0.200000  0.255556   \n",
       "513  0.811613  0.191592  0.771315  0.033868  0.633441  0.658824  0.600000   \n",
       "514  0.811613  0.191592  0.771315  0.033868  0.610932  0.647059  0.700000   \n",
       "515  0.976774  0.499311  0.711622  0.201426  0.752412  0.317647  0.400000   \n",
       "516  0.784516  0.006547  0.115867  0.019608  0.308682  0.188235  0.455556   \n",
       "\n",
       "          7         8    9   ...   18   19   20   21   22   23   24   25   26  \\\n",
       "0    0.00000  0.000000  1.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1    0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2    0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3    0.03125  0.000000  1.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4    0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "..       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "512  0.00000  0.005904  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "513  0.00000  0.049769  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "514  0.00000  0.010231  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "515  0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "516  0.00000  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "      27  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "..   ...  \n",
       "512  0.0  \n",
       "513  0.0  \n",
       "514  0.0  \n",
       "515  0.0  \n",
       "516  0.0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df2.iloc[:,0:28]\n",
    "y=df2.iloc[:,28]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da40fdd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.831897Z",
     "start_time": "2022-11-13T10:50:29.818823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "512    1.0\n",
       "513    1.0\n",
       "514    1.0\n",
       "515    0.0\n",
       "516    0.0\n",
       "Name: 28, Length: 517, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "982f9bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:29.847873Z",
     "start_time": "2022-11-13T10:50:29.835839Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4102ffa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:30.194586Z",
     "start_time": "2022-11-13T10:50:29.852212Z"
    }
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=15,input_dim=28,activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dense(units=9,activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dense(units=1,activation='sigmoid',kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94b3018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:30.242814Z",
     "start_time": "2022-11-13T10:50:30.200597Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec71dd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:49.491938Z",
     "start_time": "2022-11-13T10:50:30.256443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 2s 23ms/step - loss: 0.6908 - accuracy: 0.7094 - val_loss: 0.6870 - val_accuracy: 0.7480\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6832 - accuracy: 0.7179 - val_loss: 0.6735 - val_accuracy: 0.7480\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.6651 - accuracy: 0.7179 - val_loss: 0.6428 - val_accuracy: 0.7480\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.7179 - val_loss: 0.5966 - val_accuracy: 0.7480\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6047 - accuracy: 0.7179 - val_loss: 0.5726 - val_accuracy: 0.7480\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5975 - accuracy: 0.7179 - val_loss: 0.5651 - val_accuracy: 0.7480\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5957 - accuracy: 0.7179 - val_loss: 0.5648 - val_accuracy: 0.7480\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5938 - accuracy: 0.7179 - val_loss: 0.5654 - val_accuracy: 0.7480\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5924 - accuracy: 0.7179 - val_loss: 0.5639 - val_accuracy: 0.7480\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5914 - accuracy: 0.7179 - val_loss: 0.5640 - val_accuracy: 0.7480\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.7179 - val_loss: 0.5638 - val_accuracy: 0.7480\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.7179 - val_loss: 0.5622 - val_accuracy: 0.7480\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5909 - accuracy: 0.7179 - val_loss: 0.5612 - val_accuracy: 0.7480\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5882 - accuracy: 0.7179 - val_loss: 0.5628 - val_accuracy: 0.7480\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5861 - accuracy: 0.7179 - val_loss: 0.5616 - val_accuracy: 0.7480\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5856 - accuracy: 0.7179 - val_loss: 0.5596 - val_accuracy: 0.7480\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.7179 - val_loss: 0.5610 - val_accuracy: 0.7480\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5832 - accuracy: 0.7179 - val_loss: 0.5606 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5830 - accuracy: 0.7179 - val_loss: 0.5607 - val_accuracy: 0.7480\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5810 - accuracy: 0.7179 - val_loss: 0.5595 - val_accuracy: 0.7480\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5804 - accuracy: 0.7179 - val_loss: 0.5586 - val_accuracy: 0.7480\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5794 - accuracy: 0.7179 - val_loss: 0.5583 - val_accuracy: 0.7480\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5764 - accuracy: 0.7179 - val_loss: 0.5596 - val_accuracy: 0.7480\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5757 - accuracy: 0.7179 - val_loss: 0.5593 - val_accuracy: 0.7480\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.7179 - val_loss: 0.5582 - val_accuracy: 0.7480\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5723 - accuracy: 0.7179 - val_loss: 0.5593 - val_accuracy: 0.7480\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.7179 - val_loss: 0.5585 - val_accuracy: 0.7480\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5694 - accuracy: 0.7179 - val_loss: 0.5570 - val_accuracy: 0.7480\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5704 - accuracy: 0.7179 - val_loss: 0.5560 - val_accuracy: 0.7480\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5662 - accuracy: 0.7179 - val_loss: 0.5571 - val_accuracy: 0.7480\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5657 - accuracy: 0.7179 - val_loss: 0.5575 - val_accuracy: 0.7480\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5639 - accuracy: 0.7179 - val_loss: 0.5549 - val_accuracy: 0.7480\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5627 - accuracy: 0.7179 - val_loss: 0.5584 - val_accuracy: 0.7480\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5609 - accuracy: 0.7179 - val_loss: 0.5570 - val_accuracy: 0.7480\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5613 - accuracy: 0.7179 - val_loss: 0.5604 - val_accuracy: 0.7480\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.7179 - val_loss: 0.5580 - val_accuracy: 0.7480\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5586 - accuracy: 0.7179 - val_loss: 0.5584 - val_accuracy: 0.7480\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7179 - val_loss: 0.5584 - val_accuracy: 0.7480\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7179 - val_loss: 0.5623 - val_accuracy: 0.7480\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5550 - accuracy: 0.7179 - val_loss: 0.5605 - val_accuracy: 0.7480\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5527 - accuracy: 0.7179 - val_loss: 0.5583 - val_accuracy: 0.7480\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.7179 - val_loss: 0.5590 - val_accuracy: 0.7480\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5498 - accuracy: 0.7179 - val_loss: 0.5585 - val_accuracy: 0.7480\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7179 - val_loss: 0.5573 - val_accuracy: 0.7480\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5498 - accuracy: 0.7179 - val_loss: 0.5582 - val_accuracy: 0.7480\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5474 - accuracy: 0.7179 - val_loss: 0.5603 - val_accuracy: 0.7480\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5479 - accuracy: 0.7179 - val_loss: 0.5618 - val_accuracy: 0.7480\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7179 - val_loss: 0.5595 - val_accuracy: 0.7480\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5445 - accuracy: 0.7179 - val_loss: 0.5600 - val_accuracy: 0.7480\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5444 - accuracy: 0.7179 - val_loss: 0.5605 - val_accuracy: 0.7480\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5429 - accuracy: 0.7179 - val_loss: 0.5614 - val_accuracy: 0.7480\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.7179 - val_loss: 0.5600 - val_accuracy: 0.7480\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5407 - accuracy: 0.7179 - val_loss: 0.5611 - val_accuracy: 0.7480\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5415 - accuracy: 0.7179 - val_loss: 0.5564 - val_accuracy: 0.7480\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5377 - accuracy: 0.7179 - val_loss: 0.5596 - val_accuracy: 0.7480\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7179 - val_loss: 0.5596 - val_accuracy: 0.7480\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7179 - val_loss: 0.5554 - val_accuracy: 0.7480\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5340 - accuracy: 0.7179 - val_loss: 0.5603 - val_accuracy: 0.7480\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5331 - accuracy: 0.7179 - val_loss: 0.5571 - val_accuracy: 0.7480\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7179 - val_loss: 0.5574 - val_accuracy: 0.7480\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5315 - accuracy: 0.7179 - val_loss: 0.5576 - val_accuracy: 0.7480\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5311 - accuracy: 0.7179 - val_loss: 0.5523 - val_accuracy: 0.7480\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5315 - accuracy: 0.7179 - val_loss: 0.5556 - val_accuracy: 0.7480\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5306 - accuracy: 0.7179 - val_loss: 0.5534 - val_accuracy: 0.7480\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5273 - accuracy: 0.7179 - val_loss: 0.5522 - val_accuracy: 0.7480\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7179 - val_loss: 0.5532 - val_accuracy: 0.7480\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5241 - accuracy: 0.7179 - val_loss: 0.5532 - val_accuracy: 0.7480\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5236 - accuracy: 0.7179 - val_loss: 0.5512 - val_accuracy: 0.7480\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5227 - accuracy: 0.7564 - val_loss: 0.5519 - val_accuracy: 0.7795\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5211 - accuracy: 0.7650 - val_loss: 0.5502 - val_accuracy: 0.7795\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7650 - val_loss: 0.5493 - val_accuracy: 0.7795\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5184 - accuracy: 0.7564 - val_loss: 0.5463 - val_accuracy: 0.7795\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.7521 - val_loss: 0.5483 - val_accuracy: 0.7874\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5165 - accuracy: 0.7564 - val_loss: 0.5460 - val_accuracy: 0.7874\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5144 - accuracy: 0.7607 - val_loss: 0.5444 - val_accuracy: 0.7874\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5160 - accuracy: 0.7607 - val_loss: 0.5442 - val_accuracy: 0.7953\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5121 - accuracy: 0.7650 - val_loss: 0.5466 - val_accuracy: 0.8031\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5120 - accuracy: 0.7650 - val_loss: 0.5420 - val_accuracy: 0.7953\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5099 - accuracy: 0.7650 - val_loss: 0.5450 - val_accuracy: 0.8031\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7650 - val_loss: 0.5470 - val_accuracy: 0.7953\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5057 - accuracy: 0.7650 - val_loss: 0.5407 - val_accuracy: 0.7953\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5072 - accuracy: 0.7607 - val_loss: 0.5395 - val_accuracy: 0.7953\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5024 - accuracy: 0.7650 - val_loss: 0.5426 - val_accuracy: 0.7953\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7650 - val_loss: 0.5422 - val_accuracy: 0.7953\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7650 - val_loss: 0.5390 - val_accuracy: 0.7953\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4996 - accuracy: 0.7650 - val_loss: 0.5380 - val_accuracy: 0.7953\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4961 - accuracy: 0.7650 - val_loss: 0.5410 - val_accuracy: 0.8110\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4964 - accuracy: 0.7692 - val_loss: 0.5423 - val_accuracy: 0.8031\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4945 - accuracy: 0.7650 - val_loss: 0.5360 - val_accuracy: 0.8110\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4918 - accuracy: 0.7650 - val_loss: 0.5357 - val_accuracy: 0.8110\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7650 - val_loss: 0.5328 - val_accuracy: 0.8110\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7650 - val_loss: 0.5340 - val_accuracy: 0.8110\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4876 - accuracy: 0.7650 - val_loss: 0.5313 - val_accuracy: 0.8110\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4846 - accuracy: 0.7692 - val_loss: 0.5342 - val_accuracy: 0.8110\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4824 - accuracy: 0.7735 - val_loss: 0.5288 - val_accuracy: 0.8110\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4811 - accuracy: 0.7692 - val_loss: 0.5285 - val_accuracy: 0.8110\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7821 - val_loss: 0.5253 - val_accuracy: 0.8189\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4798 - accuracy: 0.7735 - val_loss: 0.5232 - val_accuracy: 0.8110\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.5240 - val_accuracy: 0.8189\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7778 - val_loss: 0.5236 - val_accuracy: 0.8189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195d3424a00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train, epochs=100,validation_split=.35, batch_size=10)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795f34f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:49.672170Z",
     "start_time": "2022-11-13T10:50:49.499851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7821\n",
      "accuracy: 78.21%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test,y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98039dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:51.546443Z",
     "start_time": "2022-11-13T10:50:49.681242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "#summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6710dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:52.010114Z",
     "start_time": "2022-11-13T10:50:51.562010Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor,KerasClassifier \n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cc855c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:50:52.037094Z",
     "start_time": "2022-11-13T10:50:52.019635Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=28, kernel_initializer='random_uniform', activation='relu'))\n",
    "    model.add(Dense(9, kernel_initializer='random_uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1a3e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:54:56.951734Z",
     "start_time": "2022-11-13T10:50:52.040452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\AppData\\Local\\Temp\\ipykernel_10828\\1237425172.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.933 total time=   2.4s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.750 total time=   2.3s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.524 total time=   2.6s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.680 total time=   2.7s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.699 total time=   3.1s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   7.6s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.856 total time=  12.4s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.524 total time=   6.3s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.883 total time=   7.1s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.757 total time=   6.0s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=0.990 total time=  11.3s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.817 total time=  22.2s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.961 total time=  10.7s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.893 total time=  11.7s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.874 total time=  10.4s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.750 total time=   2.1s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.680 total time=   2.1s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.990 total time=   6.9s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.875 total time=   3.7s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.767 total time=   3.8s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.816 total time=   3.6s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.854 total time=   4.0s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   6.3s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.856 total time=   6.0s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.942 total time=   6.0s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.893 total time=   6.4s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.874 total time=   6.1s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.750 total time=   1.6s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.524 total time=   1.8s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x00000195D8AB6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000195D75FA4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.699 total time=   2.1s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.971 total time=   4.1s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.788 total time=   2.6s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.680 total time=   4.3s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.757 total time=   2.7s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.816 total time=   2.6s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.990 total time=   6.6s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.827 total time=   5.9s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.932 total time=   3.9s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.854 total time=   5.0s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.883 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5de8c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:54:56.967655Z",
     "start_time": "2022-11-13T10:54:56.951734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9129014015197754, using {'batch_size': 20, 'epochs': 100}\n",
      "0.7171209812164306,0.13151203303628495 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.8041635513305664,0.15990362838451996 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9071695327758789,0.06200789202037098 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7305825233459473,0.15435061319000673 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.8604555726051331,0.07467778019698054 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9129014015197754,0.0521542518345999 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7305825233459473,0.15435061319000673 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.8024085164070129,0.09587210838637714 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.8974421262741089,0.05806547875415362 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7dab23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:56:22.814357Z",
     "start_time": "2022-11-13T10:54:56.967655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\AppData\\Local\\Temp\\ipykernel_10828\\3500408970.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.750 total time=   0.8s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.699 total time=   2.4s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.798 total time=   2.3s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.750 total time=   2.0s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.524 total time=   2.0s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.680 total time=   2.1s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.524 total time=   1.8s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.524 total time=   2.0s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.524 total time=   1.8s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.699 total time=   1.8s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.699 total time=   1.9s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.750 total time=   1.6s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.680 total time=   2.3s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.524 total time=   2.4s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.680 total time=   2.0s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.699 total time=   2.1s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.524 total time=   2.0s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.699 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(7,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x,y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01b4e4f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:56:22.855521Z",
     "start_time": "2022-11-13T10:56:22.835004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7305825233459473, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.6901979088783264,0.09266681328230858 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d05ff48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:58:17.090151Z",
     "start_time": "2022-11-13T10:56:22.866634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\AppData\\Local\\Temp\\ipykernel_10828\\3822861622.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   1.9s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   1.7s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.750 total time=   1.9s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.750 total time=   1.6s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.524 total time=   2.2s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.680 total time=   2.0s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.699 total time=   1.9s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   1.9s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   1.6s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.750 total time=   1.6s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.680 total time=   2.0s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.524 total time=   2.2s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   1.9s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=1.000 total time=   1.9s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.750 total time=   1.9s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.680 total time=   1.9s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   2.0s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   1.9s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhadra laxmi\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(9,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x,y)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21edf36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:58:17.126631Z",
     "start_time": "2022-11-13T10:58:17.108938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7305825233459473, using {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.5305825233459472,0.2757845556417363 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d77c843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:59:40.193979Z",
     "start_time": "2022-11-13T10:58:17.134396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   1.5s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.524 total time=   1.5s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   1.6s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.524 total time=   1.8s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.750 total time=   1.5s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.699 total time=   2.1s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.750 total time=   2.6s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.699 total time=   1.6s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.750 total time=   2.4s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.680 total time=   2.0s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.699 total time=   2.1s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=1.000 total time=   2.2s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.750 total time=   0.9s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.680 total time=   1.9s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.699 total time=   2.3s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   1.9s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.524 total time=   2.1s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.699 total time=   1.6s\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x,y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2457a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:59:40.225864Z",
     "start_time": "2022-11-13T10:59:40.209818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7305825233459473, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c7a6ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:59:42.660389Z",
     "start_time": "2022-11-13T10:59:40.230967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4,input_dim = 28,kernel_initializer = 'uniform',activation = 'softmax'))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(2,input_dim = 16,kernel_initializer = 'uniform',activation = 'softmax'))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(x)\n",
    "\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "191e7544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T10:59:42.681993Z",
     "start_time": "2022-11-13T10:59:42.664611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7311411992263056\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb619e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d167fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
